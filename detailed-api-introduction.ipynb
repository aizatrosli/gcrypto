{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.010991,
     "end_time": "2020-10-16T21:06:02.406829",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.395838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GResearch Crypto Forecasting\n",
    "### Introduction\n",
    "In this competition you will forecast the prices of several cyrptoassets. Once you make that prediction, you can move on to the next batch and will get additional data.\n",
    "\n",
    "This competition is different from most Kaggle Competitions in that:\n",
    "* You can only submit from Kaggle Notebooks\n",
    "* You must use our custom `gresearch_crypto` Python module.  The purpose of this module is to control the flow of information to ensure that you are not using future data to make predictions.  If you do not use this module properly, your code may fail.\n",
    "\n",
    "### This starter notebook demonstrates how to use the `gresearch_crypto` module to get the test features and make predictions.\n",
    "### TL;DR: End-to-End Usage Example\n",
    "```\n",
    "import gresearch_crypto\n",
    "env = gresearch_crypto.make_env()\n",
    "\n",
    "# Training data is in the competition dataset as usual\n",
    "train_df = pd.read_csv('/kaggle/input/g-research-crypto-forecasting/train.csv', low_memory=False)\n",
    "tgt_1_model.fit(train_df)\n",
    "tgt_2_model.fit(train_df)\n",
    "iter_test = env.iter_test()\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df['Target'] = tgt_1_model.predict(test_df)\n",
    "    env.predict(sample_prediction_df)\n",
    "```\n",
    "Note that `tgt_1_model.fit` and `tgt_2_model.fit` are examples of the functions you need to write for the above example to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009526,
     "end_time": "2020-10-16T21:06:02.426349",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.416823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "First let's import the module and create an environment. Adding the directory holding the module to the pythonpath with `sys.path.append` isn't strictly necessary within Kaggle notebooks, which handles that behind the scenes, but will be necessary if you are testing your code offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/ML/kaggle\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!pwd\n",
    "#sys.path.append(r'/mnt/e/ML/kaggle/gresearch_crypto')\n",
    "import gresearch_crypto\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can only call make_env() **once**, so don't lose it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.02778,
     "end_time": "2020-10-16T21:06:02.463894",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.436114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gresearch_crypto.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.020032,
     "end_time": "2020-10-16T21:06:02.494341",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.474309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#for dirname, _, filenames in os.walk('./'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011622,
     "end_time": "2020-10-16T21:06:02.516712",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.50509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training data is in the competition dataset as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.273123,
     "end_time": "2020-10-16T21:06:02.800188",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.527065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', low_memory=False, \n",
    "                       dtype={'Asset_ID': 'int8', 'Count': 'int32', 'row_id': 'int32', 'Count': 'int32', \n",
    "                              'Open': 'float64', 'High': 'float64', 'Low': 'float64', 'Close': 'float64', \n",
    "                              'Volume': 'float64', 'VWAP': 'float64'\n",
    "                             }\n",
    "                      )\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010818,
     "end_time": "2020-10-16T21:06:02.82238",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.811562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### `iter_test` function\n",
    "\n",
    "This is a generator which loops through each timestamp in the test set. You have direct access to the example test rows for your convenience, but your code will only be able to get rows from the real test set via the API. Once you call `predict` you can continue on to the next batch.\n",
    "\n",
    "Yields:\n",
    "* While there are more batch(es) and `predict` was called successfully since the last yield, yields a tuple of:\n",
    "    * `test_df`: DataFrame with the test features for the next batch, and user responses for the previous batch.\n",
    "    * `sample_prediction_df`: DataFrame with an example prediction.  Intended to be filled in and passed back to the `predict` function.\n",
    "* If `predict` has not been called successfully since the last yield, prints an error and yields `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018224,
     "end_time": "2020-10-16T21:06:02.851885",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.833661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can only iterate through a result from `env.iter_test()` once\n",
    "# so be careful not to lose it once you start iterating.\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011037,
     "end_time": "2020-10-16T21:06:02.874345",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.863308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's get the data for the first test batch and check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.051867,
     "end_time": "2020-10-16T21:06:02.937505",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.885638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(test_df, sample_prediction_df) = next(iter_test)\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the warning about the lack of optimization! The version of the API that will deliver the hidden test set is both more efficient and going to deliver substantially more data. It's highly recommended that you read to [the data page](https://www.kaggle.com/c/g-research-crypto-forecasting/data) timeseries section for a discussion of how to plan for the impact of the API on your notebook's runtime and memory use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026029,
     "end_time": "2020-10-16T21:06:02.975857",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.949828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_prediction_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012732,
     "end_time": "2020-10-16T21:06:03.001392",
     "exception": false,
     "start_time": "2020-10-16T21:06:02.98866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll get an error if we try to continue on to the next batch without making our predictions for the current batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.020584,
     "end_time": "2020-10-16T21:06:03.035182",
     "exception": false,
     "start_time": "2020-10-16T21:06:03.014598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "next(iter_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012685,
     "end_time": "2020-10-16T21:06:03.06105",
     "exception": false,
     "start_time": "2020-10-16T21:06:03.048365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **`predict`** function\n",
    "Stores your predictions for the current batch.  Expects the same format as `sample_prediction_df`.\n",
    "\n",
    "Args:\n",
    "* `predictions_df`: DataFrame which must have the same format as `sample_prediction_df`.\n",
    "\n",
    "This function will raise an Exception if not called after a successful iteration of the `iter_test` generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012697,
     "end_time": "2020-10-16T21:06:03.086804",
     "exception": false,
     "start_time": "2020-10-16T21:06:03.074107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's make a dummy prediction using the sample provided by `iter_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.020002,
     "end_time": "2020-10-16T21:06:03.119765",
     "exception": false,
     "start_time": "2020-10-16T21:06:03.099763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012972,
     "end_time": "2020-10-16T21:06:03.14595",
     "exception": false,
     "start_time": "2020-10-16T21:06:03.132978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Main Loop\n",
    "Let's loop through all the remaining batches in the test set generator and make the default prediction for each.  The `iter_test` generator will simply stop returning values once you've reached the end.\n",
    "\n",
    "When writing your own notebooks, be sure to write robust code that makes as few assumptions about the `iter_test`/`predict` loop as possible.  For example there may be large gaps between timestamps for one or more cryptoassets. In the unlikely event that a cryptoasset were dropped from enough exchanges it might go missing from the dataset entirely.\n",
    "\n",
    "You may assume that the structure of `sample_prediction_df` will not change in this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.363455,
     "end_time": "2020-10-16T21:06:03.522581",
     "exception": false,
     "start_time": "2020-10-16T21:06:03.159126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    sample_prediction_df['Target'] = 0\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013013,
     "end_time": "2020-10-16T21:06:03.549216",
     "exception": false,
     "start_time": "2020-10-16T21:06:03.536203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Restart the Notebook to run your code again\n",
    "In order to combat cheating you are only allowed to call `make_env` or iterate through `iter_test` once per Notebook run.  However, while you're iterating on your model it's reasonable to try something out, change the model a bit, and try it again.  Unfortunately, if you try to simply re-run the code, or even refresh the browser page, you'll still be running on the same Notebook execution session you had been running before, and the `gresearch_crypto` module will still throw errors.  To get around this you need to explicitly restart your Notebook execution session."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
